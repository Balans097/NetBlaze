## ============================================================================
## IMDB Reviews Scraper - ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ NimBrowser
## ============================================================================
## 
## Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ NimBrowser:
## 
## âœ“ CSS ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ (Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ)
## âœ“ XPath Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
## âœ“ Response Ğ¸ Selector API
## âœ“ ItemLoader Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
## âœ“ Middleware ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°
## âœ“ Pipeline Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
## âœ“ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°
## âœ“ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
## âœ“ Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
## âœ“ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹
## âœ“ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
## âœ“ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
## 
## Ğ¦ĞµĞ»ÑŒ: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ½Ğ° Ñ„Ğ¸Ğ»ÑŒĞ¼ "Terminator 3: Rise of the Machines" (2003)
## URL: https://www.imdb.com/title/tt0181852/reviews
##
## ============================================================================

import nimbrowser
import asyncdispatch
import strutils
import times
import json
import re
import tables
import sets
import httpclient

# ============================================================================
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# ============================================================================

const
  MOVIE_ID = "tt0181852"  # Terminator 3: Rise of the Machines
  BASE_URL = "https://www.imdb.com"
  REVIEWS_URL = BASE_URL & "/title/" & MOVIE_ID & "/reviews"
  MAX_PAGES = 3  # ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ´Ğ»Ñ ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ°
  REQUEST_DELAY = 2000  # Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ² Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…

# ============================================================================
# DATA PROCESSORS - ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# ============================================================================

proc cleanText(values: seq[string]): seq[string] =
  ## ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ñ‚ Ğ»Ğ¸ÑˆĞ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ² Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ² ÑÑ‚Ñ€Ğ¾Ğº
  result = @[]
  for value in values:
    var cleaned = value
    cleaned = cleaned.strip()
    cleaned = normalizeWhitespace(cleaned)
    if cleaned.len > 0:
      result.add cleaned

proc extractRating(values: seq[string]): seq[string] =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¾Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¸Ğ· ÑÑ‚Ñ€Ğ¾ĞºĞ¸ "8/10"
  result = @[]
  for value in values:
    let pattern = re"(\d+)/10"
    var matches: array[1, string]
    if value.find(pattern, matches) != -1:
      result.add matches[0]
    else:
      result.add ""

proc parseDate(values: seq[string]): seq[string] =
  ## ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ğ´Ğ°Ñ‚Ñƒ Ğ¸Ğ· Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° IMDB
  result = @[]
  for value in values:
    var cleaned = value.strip()
    # IMDB Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "12 January 2020"
    result.add cleaned

proc joinWithNewline(values: seq[string]): string =
  ## ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ¼ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
  return values.join("\n")

proc takeFirst(values: seq[string]): string =
  ## Ğ‘ĞµÑ€Ñ‘Ñ‚ Ğ¿ĞµÑ€Ğ²Ğ¾Ğµ Ğ½ĞµĞ¿ÑƒÑÑ‚Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
  for value in values:
    if value.strip().len > 0:
      return value
  return ""

proc cleanUrl(values: seq[string]): seq[string] =
  ## ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¸ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ URL Ğ² Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ñ‹Ğµ
  result = @[]
  for value in values:
    var url = value.strip()
    if url.len > 0:
      if not url.startsWith("http"):
        url = urljoin(BASE_URL, url)
      result.add url

# ============================================================================
# MIDDLEWARE - Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
# ============================================================================

type
  LoggingMiddleware = ref object of DownloaderMiddleware
    requestCount: int
    
  UserAgentMiddleware = ref object of DownloaderMiddleware
    userAgent: string

method processRequest*(m: LoggingMiddleware,
                      req: var string,
                      resp: var Response) =
  m.requestCount += 1
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  echo "â”‚ REQUEST #", m.requestCount
  echo "â”‚ URL: ", req
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

method processResponse*(m: LoggingMiddleware,
                       req: string,
                       resp: var Response) =
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  echo "â”‚ RESPONSE"
  echo "â”‚ Status: ", resp.status
  echo "â”‚ Body length: ", resp.body.len, " bytes"
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

method processRequest*(m: UserAgentMiddleware,
                      req: var string,
                      resp: var Response) =
  # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±Ñ‹ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ğ»ÑÑ User-Agent
  discard

# ============================================================================
# PIPELINES - ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# ============================================================================

type
  ValidationPipeline = ref object of Pipeline
    
  EnrichmentPipeline = ref object of Pipeline
    
  DuplicatesPipeline = ref object of Pipeline
    seenReviews: HashSet[string]

method processItem*(p: ValidationPipeline, item: var Item): bool =
  ## Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹
  echo "  [PIPELINE] Validating item..."
  
  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹
  if not item.hasKey("review_text"):
    echo "  [PIPELINE] âŒ Skipped: missing review_text"
    return false
  
  let text = $(item["review_text"])
  if text.strip().len < 10:
    echo "  [PIPELINE] âŒ Skipped: review too short"
    return false
  
  echo "  [PIPELINE] âœ“ Valid"
  return true

method processItem*(p: EnrichmentPipeline, item: var Item): bool =
  ## ĞĞ±Ğ¾Ğ³Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
  echo "  [PIPELINE] Enriching item..."
  
  # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ timestamp
  item["scraped_at"] = %($now())
  
  # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  if item.hasKey("review_text"):
    let text = $(item["review_text"])
    item["review_length"] = %(text.len)
    item["word_count"] = %(text.split().len)
  
  # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ (Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°)
  if item.hasKey("rating"):
    let rating = $(item["rating"])
    if rating.len > 0:
      try:
        let ratingValue = parseInt(rating)
        if ratingValue >= 8:
          item["sentiment"] = %"positive"
        elif ratingValue >= 5:
          item["sentiment"] = %"neutral"
        else:
          item["sentiment"] = %"negative"
      except:
        item["sentiment"] = %"unknown"
  
  echo "  [PIPELINE] âœ“ Enriched"
  return true

method processItem*(p: DuplicatesPipeline, item: var Item): bool =
  ## Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²
  if item.hasKey("review_id"):
    let reviewId = $(item["review_id"])
    if reviewId in p.seenReviews:
      echo "  [PIPELINE] âŒ Skipped: duplicate review"
      return false
    p.seenReviews.incl(reviewId)
  
  echo "  [PIPELINE] âœ“ Unique"
  return true

# ============================================================================
# SCRAPER CLASS - ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ»Ğ°ÑÑ ÑĞºÑ€ĞµĞ¹Ğ¿ĞµÑ€Ğ°
# ============================================================================

type
  IMDBReviewsScraper = ref object
    stats: ScrapingStats
    loggingMiddleware: LoggingMiddleware
    userAgentMiddleware: UserAgentMiddleware
    validationPipeline: ValidationPipeline
    enrichmentPipeline: EnrichmentPipeline
    duplicatesPipeline: DuplicatesPipeline
    allReviews: seq[Item]

proc newIMDBReviewsScraper(): IMDBReviewsScraper =
  result = IMDBReviewsScraper()
  result.stats = newScrapingStats()
  result.loggingMiddleware = LoggingMiddleware()
  result.userAgentMiddleware = UserAgentMiddleware(userAgent: "Mozilla/5.0")
  result.validationPipeline = ValidationPipeline()
  result.enrichmentPipeline = EnrichmentPipeline()
  result.duplicatesPipeline = DuplicatesPipeline()
  result.allReviews = @[]

proc extractReviewData(scraper: IMDBReviewsScraper, reviewElement: Selector): Item =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  echo "  â†’ Extracting review data..."
  
  result = initTable[string, JsonNode]()
  
  # === Ğ‘ĞĞ—ĞĞ’ĞĞ¯ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ ===
  
  # ID Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ° (Ğ¸Ğ· data-review-id Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ°)
  let reviewNode = reviewElement.node
  if not reviewNode.isNil:
    let reviewId = reviewNode.getAttr("data-review-id", "")
    if reviewId.len > 0:
      result["review_id"] = %reviewId
  
  # Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ° - Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ² ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²
  var title = reviewElement.css("a.title").get()
  if title.len == 0:
    title = reviewElement.css(".review-summary").get()
  if title.len > 0:
    result["title"] = %title.strip()
  
  # === Ğ Ğ•Ğ™Ğ¢Ğ˜ĞĞ“ ===
  
  # Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, "8/10")
  let ratingElements = reviewElement.css(".rating-other-user-rating span")
  if not ratingElements.node.isNil:
    let ratingText = ratingElements.get()
    let ratingCleaned = extractRating(@[ratingText])
    if ratingCleaned.len > 0 and ratingCleaned[0].len > 0:
      result["rating"] = %ratingCleaned[0]
  
  # === Ğ¢Ğ•ĞšĞ¡Ğ¢ ĞĞ¢Ğ—Ğ«Ğ’Ğ ===
  
  # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  var reviewText = reviewElement.css(".text.show-more__control").get()
  if reviewText.len == 0:
    reviewText = reviewElement.css(".content .text").get()
  if reviewText.len > 0:
    result["review_text"] = %normalizeWhitespace(reviewText.strip())
  
  # === Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ ĞĞ‘ ĞĞ’Ğ¢ĞĞ Ğ• ===
  
  # Ğ˜Ğ¼Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°
  var author = reviewElement.css(".display-name-link").get()
  if author.len == 0:
    author = reviewElement.css("span[itemprop='author']").get()
  if author.len > 0:
    result["author"] = %author.strip()
  
  # Ğ¡ÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°
  let authorUrl = reviewElement.css(".display-name-link").attrib("href")
  if authorUrl.len > 0:
    let absoluteUrl = urljoin(BASE_URL, authorUrl)
    result["author_url"] = %absoluteUrl
  
  # === Ğ”ĞĞ¢Ğ ĞŸĞ£Ğ‘Ğ›Ğ˜ĞšĞĞ¦Ğ˜Ğ˜ ===
  
  # Ğ”Ğ°Ñ‚Ğ° Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  let reviewDate = reviewElement.css(".review-date").get()
  if reviewDate.len > 0:
    result["review_date"] = %reviewDate.strip()
  
  # === ĞŸĞĞ›Ğ•Ğ—ĞĞĞ¡Ğ¢Ğ¬ ĞĞ¢Ğ—Ğ«Ğ’Ğ ===
  
  # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ»ÑĞ´ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸ Ğ¾Ñ‚Ğ·Ñ‹Ğ² Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¼
  let helpfulText = reviewElement.css(".actions.text-muted").get()
  if helpfulText.len > 0:
    result["helpful_count"] = %helpfulText.strip()
  
  # === Ğ¡ĞŸĞĞ™Ğ›Ğ•Ğ Ğ« ===
  
  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° ÑĞ¿Ğ¾Ğ¹Ğ»ĞµÑ€Ñ‹
  let hasSpoiler = not reviewElement.css(".spoiler-warning").node.isNil
  result["has_spoiler"] = %hasSpoiler
  
  echo "  âœ“ Review extracted"

proc scrapePage(scraper: IMDBReviewsScraper, 
                response: Response): seq[Item] =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ²ÑĞµ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ ÑĞ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
  result = @[]
  
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ PARSING PAGE"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  
  # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ĞºĞ¾Ñ€Ğ½ĞµĞ²Ğ¾Ğ¹ ÑƒĞ·ĞµĞ» Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
  if response.root.isNil:
    echo "Error: Response root is nil"
    return
  
  # CSS ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ° - Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ Ñ XmlNode Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ
  let reviewNodes = response.root.querySelectorAll(".review-container")
  
  echo "Found ", reviewNodes.len, " reviews on this page"
  echo ""
  
  for i, reviewNode in reviewNodes:
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "Review #", i + 1
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Selector Ğ¸Ğ· XmlNode
    var reviewSelector = Selector()
    new(reviewSelector)
    reviewSelector.node = reviewNode
    reviewSelector.response = response
    reviewSelector.selectorType = stCss
    
    var item = scraper.extractReviewData(reviewSelector)
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ pipelines
    var shouldSave = true
    
    # Pipeline 1: Validation
    shouldSave = scraper.validationPipeline.processItem(item)
    
    if shouldSave:
      # Pipeline 2: Deduplication
      shouldSave = scraper.duplicatesPipeline.processItem(item)
    
    if shouldSave:
      # Pipeline 3: Enrichment
      shouldSave = scraper.enrichmentPipeline.processItem(item)
    
    if shouldSave:
      result.add item
      scraper.stats.itemsScraped += 1
      echo "  âœ“ Review saved"
    
    echo ""

proc getNextPageUrl(response: Response): string =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ URL ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
  let nextButton = response.css(".load-more-trigger")
  if not nextButton.node.isNil:
    let nextKey = nextButton.attrib("data-key")
    if nextKey.len > 0:
      return REVIEWS_URL & "/_ajax?paginationKey=" & nextKey
  return ""

# ============================================================================
# MOCK DATA - Ğ”Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ±ĞµĞ· Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
# ============================================================================

proc createMockResponse(pageNum: int): Response =
  ## Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ mock Response Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ¼ HTML ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ IMDB
  let mockHtml = """
  <html>
  <body>
    <div class="review-container" data-review-id="rw123456""" & $pageNum & """">
      <div class="review-header">
        <a class="title" href="/review/rw123456""" & $pageNum & """">
          Best action movie of 2003!
        </a>
        <span class="rating-other-user-rating">
          <span>9</span>/10
        </span>
      </div>
      <div class="content">
        <div class="text show-more__control">
          This movie is absolutely fantastic! Arnold Schwarzenegger returns as the T-800 in an epic battle. 
          The action sequences are intense and well-choreographed. The plot keeps you on the edge of your seat. 
          Highly recommended for Terminator fans!
        </div>
        <div class="review-author">
          <span itemprop="author">
            <a class="display-name-link" href="/user/ur12345""" & $pageNum & """">
              JohnDoe""" & $pageNum & """
            </a>
          </span>
        </div>
        <span class="review-date">15 January 2020</span>
        <div class="actions text-muted">
          542 out of 678 found this helpful
        </div>
      </div>
    </div>
    
    <div class="review-container" data-review-id="rw234567""" & $pageNum & """">
      <div class="review-header">
        <a class="title" href="/review/rw234567""" & $pageNum & """">
          Good but not great
        </a>
        <span class="rating-other-user-rating">
          <span>6</span>/10
        </span>
      </div>
      <div class="content">
        <div class="text show-more__control">
          The movie has great action scenes, but the plot is a bit predictable.
          Arnold is good, but I expected more character development.
        </div>
        <div class="spoiler-warning">Warning: Contains spoilers</div>
        <div class="review-author">
          <span itemprop="author">
            <a class="display-name-link" href="/user/ur67890""" & $pageNum & """">
              MovieCritic""" & $pageNum & """
            </a>
          </span>
        </div>
        <span class="review-date">22 March 2019</span>
        <div class="actions text-muted">
          123 out of 234 found this helpful
        </div>
      </div>
    </div>
    
    <div class="review-container" data-review-id="rw345678""" & $pageNum & """">
      <div class="review-header">
        <a class="title" href="/review/rw345678""" & $pageNum & """">
          Amazing sci-fi action!
        </a>
        <span class="rating-other-user-rating">
          <span>10</span>/10
        </span>
      </div>
      <div class="content">
        <div class="text show-more__control">
          Perfect movie from start to finish. The special effects are incredible, 
          the soundtrack is memorable, and the story is engaging. 
          This is how sci-fi action should be made!
        </div>
        <div class="review-author">
          <span itemprop="author">
            <a class="display-name-link" href="/user/ur11111""" & $pageNum & """">
              ActionFan""" & $pageNum & """
            </a>
          </span>
        </div>
        <span class="review-date">5 July 2018</span>
        <div class="actions text-muted">
          892 out of 945 found this helpful
        </div>
      </div>
    </div>
    
    """ & (if pageNum < MAX_PAGES: """<button class="load-more-trigger" data-key="page""" & $(pageNum + 1) & """"></button>""" else: "") & """
  </body>
  </html>
  """
  
  result = newResponse(
    url = REVIEWS_URL & (if pageNum > 1: "?page=" & $pageNum else: ""),
    status = 200,
    headers = newHttpHeaders(),
    body = mockHtml
  )

proc scrapeAllPages(scraper: IMDBReviewsScraper) {.async.} =
  ## Ğ¡ĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ñ‚ Ğ²ÑĞµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ STARTING SCRAPING SESSION"
  echo "â•‘ Movie: Terminator 3: Rise of the Machines (2003)"
  echo "â•‘ URL: ", REVIEWS_URL
  echo "â•‘ Max pages: ", MAX_PAGES
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  
  var currentPage = 1
  var currentUrl = REVIEWS_URL
  
  while currentPage <= MAX_PAGES:
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "â•‘ PAGE ", currentPage, " / ", MAX_PAGES
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    # Middleware: processRequest
    var request = currentUrl
    var dummyResponse: Response
    scraper.loggingMiddleware.processRequest(request, dummyResponse)
    scraper.userAgentMiddleware.processRequest(request, dummyResponse)
    
    # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±Ñ‹Ğ» Ğ±Ñ‹ fetchAsync
    # let response = await fetchAsync(currentUrl)
    
    # Ğ”Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ mock Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    let response = createMockResponse(currentPage)
    
    scraper.stats.requestsCount += 1
    
    # Middleware: processResponse
    scraper.loggingMiddleware.processResponse(request, response)
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²
    let reviews = scraper.scrapePage(response)
    scraper.allReviews.add reviews
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ URL ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
    currentUrl = getNextPageUrl(response)
    
    if currentUrl.len == 0 or currentPage >= MAX_PAGES:
      break
    
    currentPage += 1
    
    # Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
    if currentPage <= MAX_PAGES:
      echo "â³ Waiting ", REQUEST_DELAY, "ms before next page..."
      await sleepAsync(REQUEST_DELAY)
  
  scraper.stats.finish()

# ============================================================================
# EXPORT AND REPORTING
# ============================================================================

proc exportResults(scraper: IMDBReviewsScraper) =
  ## Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ EXPORTING RESULTS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  
  # JSON
  echo "  â†’ Exporting to JSON..."
  let jsonData = %scraper.allReviews
  writeFile("imdb_reviews.json", $jsonData.pretty())
  echo "  âœ“ Saved: imdb_reviews.json"
  
  # JSON Lines
  echo "  â†’ Exporting to JSON Lines..."
  let jsonLines = scraper.allReviews.toJsonLines()
  writeFile("imdb_reviews.jsonl", jsonLines)
  echo "  âœ“ Saved: imdb_reviews.jsonl"
  
  # CSV
  echo "  â†’ Exporting to CSV..."
  let headers = @[
    "review_id", "title", "rating", "review_text",
    "author", "review_date", "helpful_count",
    "sentiment", "word_count", "scraped_at"
  ]
  let csvData = scraper.allReviews.toCsv(headers)
  writeFile("imdb_reviews.csv", csvData)
  echo "  âœ“ Saved: imdb_reviews.csv"

proc printStatistics(scraper: IMDBReviewsScraper) =
  ## Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ°
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SCRAPING STATISTICS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  echo "  ğŸ“Š Total requests:      ", scraper.stats.requestsCount
  echo "  ğŸ“ Reviews scraped:     ", scraper.stats.itemsScraped
  echo "  â±ï¸  Duration:            ", scraper.stats.duration()
  echo "  ğŸ¯ Success rate:        ", 
    if scraper.stats.requestsCount > 0:
      formatFloat(
        scraper.stats.itemsScraped.float / scraper.stats.requestsCount.float * 100,
        ffDecimal, 2
      ) & "%"
    else: "N/A"
  echo ""
  
  # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ°Ğ¼
  var ratingCounts = initTable[string, int]()
  var sentimentCounts = initTable[string, int]()
  var totalWordCount = 0
  
  for review in scraper.allReviews:
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ¾Ğ²
    if review.hasKey("rating"):
      let rating = $(review["rating"])
      if rating.len > 0:
        ratingCounts[rating] = ratingCounts.getOrDefault(rating, 0) + 1
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
    if review.hasKey("sentiment"):
      let sentiment = $(review["sentiment"])
      sentimentCounts[sentiment] = sentimentCounts.getOrDefault(sentiment, 0) + 1
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ ÑĞ»Ğ¾Ğ²
    if review.hasKey("word_count"):
      let wc = $(review["word_count"])
      try:
        totalWordCount += parseInt(wc)
      except:
        discard
  
  echo "  ğŸ“ˆ RATINGS DISTRIBUTION:"
  for rating in ["10", "9", "8", "7", "6", "5", "4", "3", "2", "1"]:
    if ratingCounts.hasKey(rating):
      let count = ratingCounts[rating]
      let bar = "â–ˆ".repeat(count)
      echo "     ", rating, "/10: ", bar, " (", count, ")"
  
  echo ""
  echo "  ğŸ˜Š SENTIMENT ANALYSIS:"
  for sentiment in ["positive", "neutral", "negative", "unknown"]:
    if sentimentCounts.hasKey(sentiment):
      let count = sentimentCounts[sentiment]
      echo "     ", sentiment.capitalizeAscii(), ": ", count
  
  echo ""
  echo "  âœï¸  AVERAGE REVIEW LENGTH: ", 
    if scraper.allReviews.len > 0:
      $(totalWordCount div scraper.allReviews.len) & " words"
    else: "N/A"
  echo ""

proc printSampleReviews(scraper: IMDBReviewsScraper, count: int = 2) =
  ## Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SAMPLE REVIEWS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  
  let samplesToShow = min(count, scraper.allReviews.len)
  
  for i in 0..<samplesToShow:
    let review = scraper.allReviews[i]
    
    echo "  â”Œâ”€ Review #", i + 1, " ", "â”€".repeat(60)
    
    if review.hasKey("title"):
      echo "  â”‚ ğŸ“Œ Title: ", $(review["title"])
    
    if review.hasKey("rating"):
      echo "  â”‚ â­ Rating: ", $(review["rating"]), "/10"
    
    if review.hasKey("author"):
      echo "  â”‚ ğŸ‘¤ Author: ", $(review["author"])
    
    if review.hasKey("review_date"):
      echo "  â”‚ ğŸ“… Date: ", $(review["review_date"])
    
    if review.hasKey("sentiment"):
      echo "  â”‚ ğŸ˜Š Sentiment: ", $(review["sentiment"])
    
    if review.hasKey("word_count"):
      echo "  â”‚ âœï¸  Words: ", $(review["word_count"])
    
    if review.hasKey("review_text"):
      var text = $(review["review_text"])
      if text.len > 200:
        text = text[0..200] & "..."
      echo "  â”‚"
      echo "  â”‚ ğŸ“ Review:"
      for line in text.split("\n"):
        if line.strip().len > 0:
          echo "  â”‚    ", line
    
    echo "  â””â”€", "â”€".repeat(70)
    echo ""

# ============================================================================
# MAIN - Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°
# ============================================================================

proc main() {.async.} =
  echo """
  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘                                                                        â•‘
  â•‘              IMDB REVIEWS SCRAPER - NimBrowser Demo                    â•‘
  â•‘                                                                        â•‘
  â•‘  Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ NimBrowser v1.0                 â•‘
  â•‘                                                                        â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  """
  echo ""
  
  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞºÑ€ĞµĞ¹Ğ¿ĞµÑ€Ğ°
  let scraper = newIMDBReviewsScraper()
  
  # Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ĞºÑÑˆĞ° ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²
  enableQueryCache()
  echo "âœ“ Query cache enabled"
  echo ""
  
  # Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ°
  await scraper.scrapeAllPages()
  
  # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
  scraper.exportResults()
  
  # Ğ’Ñ‹Ğ²Ğ¾Ğ´ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
  scraper.printStatistics()
  
  # Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²
  scraper.printSampleReviews(2)
  
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SCRAPING COMPLETED SUCCESSFULLY! ğŸ‰"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  echo "Files created:"
  echo "  â€¢ imdb_reviews.json  - ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ JSON Ğ¼Ğ°ÑÑĞ¸Ğ²"
  echo "  â€¢ imdb_reviews.jsonl - JSON Lines Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚"
  echo "  â€¢ imdb_reviews.csv   - CSV Ñ„Ğ°Ğ¹Ğ»"
  echo ""

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹
when isMainModule:
  waitFor main()

## ============================================================================
## Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ˜ ĞŸĞ Ğ—ĞĞŸĞ£Ğ¡ĞšĞ£
## ============================================================================
##
## 1. Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ñƒ Ğ²Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Nim (Ğ²ĞµÑ€ÑĞ¸Ñ 1.6.0 Ğ¸Ğ»Ğ¸ Ğ²Ñ‹ÑˆĞµ)
##
## 2. Ğ¡ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ:
##    nim c -d:release imdb_reviews_scraper.nim
##
## 3. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ:
##    ./imdb_reviews_scraper
##
## ĞŸĞ Ğ˜ĞœĞ•Ğ§ĞĞĞ˜Ğ•: Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ mock Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸.
## Ğ”Ğ»Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ° IMDB:
##   - Ğ Ğ°ÑĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ñ fetchAsync()
##   - Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ±Ğ»ÑĞ´Ğ°ĞµÑ‚Ğµ robots.txt
##   - Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
##   - Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ¸
##
## ============================================================================
