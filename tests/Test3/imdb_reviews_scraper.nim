## ============================================================================
## IMDB Reviews Scraper - ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ NimBrowser
## ============================================================================
## 
## Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²ÑĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ NimBrowser:
## 
## âœ“ CSS ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ (Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ)
## âœ“ XPath Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
## âœ“ Response Ğ¸ Selector API
## âœ“ ItemLoader Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
## âœ“ Middleware ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°
## âœ“ Pipeline Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
## âœ“ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°
## âœ“ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
## âœ“ Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
## âœ“ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹
## âœ“ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
## âœ“ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
## 
## Ğ¦ĞµĞ»ÑŒ: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ½Ğ° Ñ„Ğ¸Ğ»ÑŒĞ¼ "Terminator 3: Rise of the Machines" (2003)
## URL: https://www.imdb.com/title/tt0181852/reviews
##
## ============================================================================

import nimbrowser
import asyncdispatch
import httpclient
import strutils
import times
import json
import re
import tables
import sets
import xmltree except innerText
import htmlparser except normalizeWhitespace
import streams

# ============================================================================
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# ============================================================================

const
  MOVIE_ID = "tt0181852"  # Terminator 3: Rise of the Machines
  BASE_URL = "https://www.imdb.com"
  REVIEWS_URL = BASE_URL & "/title/" & MOVIE_ID & "/reviews"
  MAX_PAGES = 50  # ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ´Ğ»Ñ ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ° (Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ ~25 Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ² Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ)
  REQUEST_DELAY = 2000  # Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ² Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…

# ============================================================================
# DATA PROCESSORS - ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# ============================================================================

proc cleanText(values: seq[string]): seq[string] =
  ## ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ñ‚ Ğ»Ğ¸ÑˆĞ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ² Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ² ÑÑ‚Ñ€Ğ¾Ğº
  result = @[]
  for value in values:
    var cleaned = value
    cleaned = cleaned.strip()
    cleaned = normalizeWhitespace(cleaned)
    if cleaned.len > 0:
      result.add cleaned

proc extractRating(values: seq[string]): seq[string] =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¾Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ¸Ğ· ÑÑ‚Ñ€Ğ¾ĞºĞ¸ "8/10"
  result = @[]
  for value in values:
    let pattern = re"(\d+)/10"
    var matches: array[1, string]
    if value.find(pattern, matches) != -1:
      result.add matches[0]
    else:
      result.add ""

proc parseDate(values: seq[string]): seq[string] =
  ## ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ğ´Ğ°Ñ‚Ñƒ Ğ¸Ğ· Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° IMDB
  result = @[]
  for value in values:
    var cleaned = value.strip()
    # IMDB Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "12 January 2020"
    result.add cleaned

proc joinWithNewline(values: seq[string]): string =
  ## ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ¼ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
  return values.join("\n")

proc takeFirst(values: seq[string]): string =
  ## Ğ‘ĞµÑ€Ñ‘Ñ‚ Ğ¿ĞµÑ€Ğ²Ğ¾Ğµ Ğ½ĞµĞ¿ÑƒÑÑ‚Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
  for value in values:
    if value.strip().len > 0:
      return value
  return ""

proc cleanUrl(values: seq[string]): seq[string] =
  ## ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¸ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ URL Ğ² Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ñ‹Ğµ
  result = @[]
  for value in values:
    var url = value.strip()
    if url.len > 0:
      if not url.startsWith("http"):
        url = urljoin(BASE_URL, url)
      result.add url

# ============================================================================
# MIDDLEWARE - Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
# ============================================================================

type
  LoggingMiddleware = ref object of DownloaderMiddleware
    requestCount: int
    
  UserAgentMiddleware = ref object of DownloaderMiddleware
    userAgent: string

method processRequest*(m: LoggingMiddleware,
                      req: var string,
                      resp: var nimbrowser.Response) =
  m.requestCount += 1
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  echo "â”‚ REQUEST #", m.requestCount
  echo "â”‚ URL: ", req
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

method processResponse*(m: LoggingMiddleware,
                       req: string,
                       resp: var nimbrowser.Response) =
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  echo "â”‚ RESPONSE"
  echo "â”‚ Status: ", resp.status
  echo "â”‚ Body length: ", resp.body.len, " bytes"
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

method processRequest*(m: UserAgentMiddleware,
                      req: var string,
                      resp: var nimbrowser.Response) =
  # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±Ñ‹ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ğ»ÑÑ User-Agent
  discard

# ============================================================================
# PIPELINES - ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
# ============================================================================

type
  ValidationPipeline = ref object of Pipeline
    
  EnrichmentPipeline = ref object of Pipeline
    
  DuplicatesPipeline = ref object of Pipeline
    seenReviews: HashSet[string]

method processItem*(p: ValidationPipeline, item: var Item): bool =
  ## Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹
  echo "  [PIPELINE] Validating item..."
  
  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹
  if not item.hasKey("review_text"):
    echo "  [PIPELINE] âŒ Skipped: missing review_text"
    return false
  
  let text = $(item["review_text"])
  if text.strip().len < 10:
    echo "  [PIPELINE] âŒ Skipped: review too short"
    return false
  
  echo "  [PIPELINE] âœ“ Valid"
  return true

method processItem*(p: EnrichmentPipeline, item: var Item): bool =
  ## ĞĞ±Ğ¾Ğ³Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
  echo "  [PIPELINE] Enriching item..."
  
  # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ timestamp
  item["scraped_at"] = %($now())
  
  # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  if item.hasKey("review_text"):
    let text = $(item["review_text"])
    item["review_length"] = %(text.len)
    item["word_count"] = %(text.split().len)
  
  # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ (Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°)
  if item.hasKey("rating"):
    let rating = $(item["rating"])
    if rating.len > 0:
      try:
        let ratingValue = parseInt(rating)
        if ratingValue >= 8:
          item["sentiment"] = %"positive"
        elif ratingValue >= 5:
          item["sentiment"] = %"neutral"
        else:
          item["sentiment"] = %"negative"
      except:
        item["sentiment"] = %"unknown"
  
  echo "  [PIPELINE] âœ“ Enriched"
  return true

method processItem*(p: DuplicatesPipeline, item: var Item): bool =
  ## Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²
  if item.hasKey("review_id"):
    let reviewId = $(item["review_id"])
    if reviewId in p.seenReviews:
      echo "  [PIPELINE] âŒ Skipped: duplicate review"
      return false
    p.seenReviews.incl(reviewId)
  
  echo "  [PIPELINE] âœ“ Unique"
  return true

# ============================================================================
# SCRAPER CLASS - ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ»Ğ°ÑÑ ÑĞºÑ€ĞµĞ¹Ğ¿ĞµÑ€Ğ°
# ============================================================================

type
  IMDBReviewsScraper = ref object
    stats: ScrapingStats
    loggingMiddleware: LoggingMiddleware
    userAgentMiddleware: UserAgentMiddleware
    validationPipeline: ValidationPipeline
    enrichmentPipeline: EnrichmentPipeline
    duplicatesPipeline: DuplicatesPipeline
    allReviews: seq[Item]

proc newIMDBReviewsScraper(): IMDBReviewsScraper =
  result = IMDBReviewsScraper()
  result.stats = newScrapingStats()
  result.loggingMiddleware = LoggingMiddleware()
  result.userAgentMiddleware = UserAgentMiddleware(userAgent: "Mozilla/5.0")
  result.validationPipeline = ValidationPipeline()
  result.enrichmentPipeline = EnrichmentPipeline()
  result.duplicatesPipeline = DuplicatesPipeline()
  result.allReviews = @[]

proc extractReviewData(scraper: IMDBReviewsScraper, reviewElement: Selector): Item =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  echo "  â†’ Extracting review data..."
  
  result = initTable[string, JsonNode]()
  
  # === Ğ‘ĞĞ—ĞĞ’ĞĞ¯ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ ===
  
  # ID Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ° (Ğ¸Ğ· data-review-id Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ°)
  let reviewNode = reviewElement.node
  if reviewNode.isNil:
    echo "    âœ— reviewNode is nil"
    return result
  
  let reviewId = reviewNode.getAttr("data-review-id", "")
  if reviewId.len > 0:
    result["review_id"] = %reviewId
    echo "    â€¢ review_id: ", reviewId
  
  # === Ğ˜Ğ—Ğ’Ğ›Ğ•Ğ§Ğ•ĞĞ˜Ğ• Ğ”ĞĞĞĞ«Ğ¥ Ğ§Ğ•Ğ Ğ•Ğ— ĞŸĞĞ˜Ğ¡Ğš Ğ’ DOM ===
  
  # Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  for node in reviewNode.findAll("a"):
    if node.kind == xnElement and node.attr("class").contains("title"):
      let titleText = node.innerText().strip()
      if titleText.len > 0:
        result["title"] = %titleText
        echo "    â€¢ title: ", titleText
        break
  
  # Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³
  for node in reviewNode.findAll("span"):
    if node.kind == xnElement and node.attr("class").contains("rating-other-user-rating"):
      for subNode in node.findAll("span"):
        if subNode.kind == xnElement:
          let ratingText = subNode.innerText().strip()
          let pattern = re"(\d+)/10"
          var matches: array[1, string]
          if ratingText.find(pattern, matches) != -1:
            result["rating"] = %matches[0]
            echo "    â€¢ rating: ", matches[0]
            break
      break
  
  # Ğ¢ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  for node in reviewNode.findAll("div"):
    if node.kind == xnElement and node.attr("class").contains("text") and node.attr("class").contains("show-more__control"):
      let reviewText = node.innerText().strip()
      if reviewText.len > 0:
        result["review_text"] = %reviewText
        echo "    â€¢ review_text: ", reviewText[0..min(50, reviewText.len-1)], "..."
        break
  
  # ĞĞ²Ñ‚Ğ¾Ñ€
  for node in reviewNode.findAll("span"):
    if node.kind == xnElement and node.attr("class").contains("display-name-link"):
      for linkNode in node.findAll("a"):
        if linkNode.kind == xnElement:
          let authorText = linkNode.innerText().strip()
          if authorText.len > 0:
            result["author"] = %authorText
            echo "    â€¢ author: ", authorText
          
          # URL Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°
          let href = linkNode.attr("href")
          if href.len > 0:
            var authorUrl = href
            if not authorUrl.startsWith("http"):
              authorUrl = urljoin(BASE_URL, authorUrl)
            result["author_url"] = %authorUrl
            echo "    â€¢ author_url: ", authorUrl
          break
      break
  
  # Ğ”Ğ°Ñ‚Ğ° Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  for node in reviewNode.findAll("span"):
    if node.kind == xnElement and node.attr("class").contains("review-date"):
      let dateText = node.innerText().strip()
      if dateText.len > 0:
        result["review_date"] = %dateText
        echo "    â€¢ review_date: ", dateText
        break
  
  # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ "Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ñ…" Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²
  for node in reviewNode.findAll("div"):
    if node.kind == xnElement and node.attr("class").contains("actions") and node.attr("class").contains("text-muted"):
      let helpfulText = node.innerText().strip()
      if helpfulText.len > 0:
        result["helpful_count"] = %helpfulText
        echo "    â€¢ helpful_count: ", helpfulText
        break
  
  # === SPOILER WARNING ===
  
  # Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ spoiler Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
  var hasSpoiler = false
  for node in reviewNode.findAll("span"):
    if node.kind == xnElement and node.attr("class").contains("spoiler-warning"):
      hasSpoiler = true
      break
  
  result["has_spoiler"] = %hasSpoiler
  if hasSpoiler:
    echo "    â€¢ has_spoiler: true"
  
  echo "    âœ“ Data extracted"

proc scrapePage(scraper: IMDBReviewsScraper, response: nimbrowser.Response): seq[Item] =
  ## Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ²ÑĞµ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ ÑĞ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SCRAPING PAGE"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  
  result = @[]
  
  # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ HTML Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ñ€Ğ°Ğ·)
  if scraper.stats.requestsCount == 1:
    try:
      writeFile("imdb_page_debug.html", response.body)
      echo "  [DEBUG] HTML saved to imdb_page_debug.html"
    except:
      discard
  
  # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ° Ğ¸Ğ· HTML
  let rootNode = parseHtml(response.body)
  
  # ĞŸĞ¾Ğ¸ÑĞº Ğ²ÑĞµÑ… Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸
  echo "  â†’ Searching for review elements..."
  
  if rootNode.isNil:
    echo "  âœ“ Found 0 reviews"
    return result
  
  # IMDB Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ» ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ - Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ĞºĞ»Ğ°ÑÑÑ‹
  # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ article ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ»Ğ¸ div Ñ data-testid
  var reviewNodes: seq[XmlNode] = @[]
  
  # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: Ğ¸Ñ‰ĞµĞ¼ div Ñ ĞºĞ»Ğ°ÑÑĞ¾Ğ¼ lister-item
  for node in rootNode.findAll("div"):
    if node.kind == xnElement:
      let className = node.attr("class")
      if className.contains("lister-item") or className.contains("review-container"):
        reviewNodes.add(node)
  
  # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸, Ğ¸Ñ‰ĞµĞ¼ article
  if reviewNodes.len == 0:
    for node in rootNode.findAll("article"):
      if node.kind == xnElement:
        reviewNodes.add(node)
  
  # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 3: Ğ¸Ñ‰ĞµĞ¼ div Ñ data-testid="review-card"
  if reviewNodes.len == 0:
    for node in rootNode.findAll("div"):
      if node.kind == xnElement:
        if node.attr("data-testid").contains("review"):
          reviewNodes.add(node)
  
  echo "  âœ“ Found ", reviewNodes.len, " reviews"
  
  # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°
  for i, reviewNode in reviewNodes:
    echo ""
    echo "  â”Œâ”€ Processing review #", i + 1, " â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Selector Ğ¸Ğ· ÑƒĞ·Ğ»Ğ°
    let reviewElement = Selector(node: reviewNode)
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    var item = scraper.extractReviewData(reviewElement)
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ pipelines
    var shouldKeep = true
    
    # Pipeline 1: Validation
    if not scraper.validationPipeline.processItem(item):
      shouldKeep = false
    
    # Pipeline 2: Deduplication
    if shouldKeep and not scraper.duplicatesPipeline.processItem(item):
      shouldKeep = false
    
    # Pipeline 3: Enrichment
    if shouldKeep and not scraper.enrichmentPipeline.processItem(item):
      shouldKeep = false
    
    if shouldKeep:
      result.add item
      scraper.stats.itemsScraped += 1
      echo "  â”‚ âœ“ Review added to results"
    else:
      echo "  â”‚ âœ— Review filtered out"
    
    echo "  â””â”€", "â”€".repeat(60)
  
  echo ""
  echo "  ğŸ“Š Page summary: ", result.len, " reviews accepted, ",
       reviewNodes.len - result.len, " filtered out"

proc getNextPageUrl(response: nimbrowser.Response): string =
  ## ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ URL ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¸Ğ· Ğ¿Ğ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
  result = ""
  
  let rootNode = parseHtml(response.body)
  if rootNode.isNil:
    return result
  
  # IMDB Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ data-key Ğ´Ğ»Ñ Ğ¿Ğ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğµ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Load More
  # Ğ˜Ñ‰ĞµĞ¼ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ñ ĞºĞ»Ğ°ÑÑĞ¾Ğ¼ load-more-data
  for node in rootNode.findAll("button"):
    if node.kind == xnElement:
      let className = node.attr("class")
      if className.contains("load-more-data") or className.contains("ipc-see-more"):
        let dataKey = node.attr("data-key")
        if dataKey.len > 0:
          # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ URL Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
          result = REVIEWS_URL & "?paginationKey=" & dataKey
          return result
  
  # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ñ‡ĞµÑ€ĞµĞ· div Ñ id load-more-trigger
  for node in rootNode.findAll("div"):
    if node.kind == xnElement:
      if node.attr("id") == "load-more-trigger":
        let dataKey = node.attr("data-key")
        if dataKey.len > 0:
          result = REVIEWS_URL & "?paginationKey=" & dataKey
          return result

proc createMockResponse(pageNum: int): nimbrowser.Response =
  ## Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ mock Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
  new(result)
  result.url = REVIEWS_URL
  result.status = 200
  result.encoding = "utf-8"
  result.meta = initTable[string, string]()
  result.body = """
<html>
<body>
  <div class="review-container" data-review-id="rv123456">
    <div class="lister-item-content">
      <a class="title">Great action sequences!</a>
      <span class="rating-other-user-rating">
        <span>8/10</span>
      </span>
      <div class="text show-more__control">
        This is one of the most underrated Terminator movies. The action is spectacular 
        and the special effects still hold up today. Arnold Schwarzenegger gives a solid 
        performance as always. While it may not reach the heights of T2, it's still a 
        very entertaining film that delivers on the promise of robot action.
      </div>
      <span class="display-name-link">
        <a href="/user/ur12345678/">ActionFan2003</a>
      </span>
      <span class="review-date">15 July 2003</span>
      <div class="actions text-muted">125 out of 150 found this helpful</div>
    </div>
  </div>
  
  <div class="review-container" data-review-id="rv123457">
    <div class="lister-item-content">
      <a class="title">Not as good as T2, but still fun</a>
      <span class="rating-other-user-rating">
        <span>6/10</span>
      </span>
      <div class="text show-more__control">
        After the masterpiece that was Terminator 2, this third installment feels 
        somewhat unnecessary. However, if you can look past that, there's still 
        plenty to enjoy here. The chase scenes are well-done and the darker ending 
        was a nice surprise. Worth watching for fans of the franchise.
      </div>
      <span class="display-name-link">
        <a href="/user/ur87654321/">MovieBuff1999</a>
      </span>
      <span class="review-date">22 July 2003</span>
      <div class="actions text-muted">89 out of 120 found this helpful</div>
      <span class="spoiler-warning">Contains spoilers</span>
    </div>
  </div>
  
  <div class="review-container" data-review-id="rv123458">
    <div class="lister-item-content">
      <a class="title">Disappointing sequel</a>
      <span class="rating-other-user-rating">
        <span>4/10</span>
      </span>
      <div class="text show-more__control">
        I had high hopes for this movie, but it just doesn't capture the magic 
        of the first two films. The plot feels recycled and the new characters 
        aren't very interesting. Some decent action scenes can't save this from 
        being a mediocre entry in the series.
      </div>
      <span class="display-name-link">
        <a href="/user/ur11223344/">CriticCorner</a>
      </span>
      <span class="review-date">1 August 2003</span>
      <div class="actions text-muted">45 out of 95 found this helpful</div>
    </div>
  </div>
</body>
</html>
"""
  result.headers = newHttpHeaders({"Content-Type": "text/html; charset=utf-8"})

# ============================================================================
# HTTP REQUEST HELPERS
# ============================================================================

proc fetchWithHeaders(url: string): Future[nimbrowser.Response] {.async.} =
  ## Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼Ğ¸
  var headers = newHttpHeaders({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1"
  })
  
  var client = newAsyncHttpClient()
  client.headers = headers
  
  try:
    let httpResponse = await client.get(url)
    let bodyText = await httpResponse.body
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Response Ğ¾Ğ±ÑŠĞµĞºÑ‚ NimBrowser
    new(result)
    result.url = url
    result.status = httpResponse.code.int
    result.body = bodyText
    result.encoding = "utf-8"
    result.meta = initTable[string, string]()
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
    for key, val in httpResponse.headers.table:
      result.meta[key] = val.join("; ")
    
    client.close()
  except Exception as e:
    echo "Error fetching URL: ", e.msg
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹
    new(result)
    result.url = url
    result.status = 500
    result.body = ""
    result.encoding = "utf-8"
    result.meta = initTable[string, string]()
    client.close()

# ============================================================================
# SCRAPING LOGIC
# ============================================================================

proc scrapeAllPages(scraper: IMDBReviewsScraper) {.async.} =
  ## Ğ¡ĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ñ‚ Ğ²ÑĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ STARTING SCRAPING PROCESS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  echo "  ğŸ¯ Target: ", REVIEWS_URL
  echo "  ğŸ“„ Max pages: ", MAX_PAGES
  echo "  â±ï¸  Delay: ", REQUEST_DELAY, "ms"
  echo ""
  
  var currentUrl = REVIEWS_URL
  var currentPage = 1
  
  while currentUrl.len > 0:
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "â•‘ PAGE #", currentPage
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    # Middleware: processRequest
    var request = currentUrl
    var dummyResponse = new(nimbrowser.Response)
    scraper.loggingMiddleware.processRequest(request, dummyResponse)
    
    # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼Ğ¸
    let response = await fetchWithHeaders(currentUrl)
    
    scraper.stats.requestsCount += 1
    
    # Middleware: processResponse
    var mutableResponse = response
    scraper.loggingMiddleware.processResponse(request, mutableResponse)
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²
    let reviews = scraper.scrapePage(response)
    scraper.allReviews.add reviews
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ URL ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
    currentUrl = getNextPageUrl(response)
    
    if currentUrl.len == 0 or currentPage >= MAX_PAGES:
      break
    
    currentPage += 1
    
    # Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
    if currentPage <= MAX_PAGES:
      echo "â³ Waiting ", REQUEST_DELAY, "ms before next page..."
      await sleepAsync(REQUEST_DELAY)
  
  # scraper.stats.finish()

# ============================================================================
# EXPORT AND REPORTING
# ============================================================================

proc exportResults(scraper: IMDBReviewsScraper) =
  ## Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ EXPORTING RESULTS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  
  # JSON
  echo "  â†’ Exporting to JSON..."
  let jsonData = %scraper.allReviews
  writeFile("imdb_reviews.json", $jsonData.pretty())
  echo "  âœ“ Saved: imdb_reviews.json"
  
  # JSON Lines
  echo "  â†’ Exporting to JSON Lines..."
  let jsonLines = scraper.allReviews.toJsonLines()
  writeFile("imdb_reviews.jsonl", jsonLines)
  echo "  âœ“ Saved: imdb_reviews.jsonl"
  
  # CSV
  echo "  â†’ Exporting to CSV..."
  let headers = @[
    "review_id", "title", "rating", "review_text",
    "author", "review_date", "helpful_count",
    "sentiment", "word_count", "scraped_at"
  ]
  let csvData = scraper.allReviews.toCsv(headers)
  writeFile("imdb_reviews.csv", csvData)
  echo "  âœ“ Saved: imdb_reviews.csv"

proc printStatistics(scraper: IMDBReviewsScraper) =
  ## Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ°
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SCRAPING STATISTICS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  echo "  ğŸ“Š Total requests:      ", scraper.stats.requestsCount
  echo "  ğŸ“ Reviews scraped:     ", scraper.stats.itemsScraped
  # echo "  â±ï¸  Duration:            ", scraper.stats.duration()
  echo "  ğŸ¯ Success rate:        ", 
    if scraper.stats.requestsCount > 0:
      formatFloat(
        scraper.stats.itemsScraped.float / scraper.stats.requestsCount.float * 100,
        ffDecimal, 2
      ) & "%"
    else: "N/A"
  echo ""
  
  # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ°Ğ¼
  var ratingCounts = initTable[string, int]()
  var sentimentCounts = initTable[string, int]()
  var totalWordCount = 0
  
  for review in scraper.allReviews:
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ¾Ğ²
    if review.hasKey("rating"):
      let rating = $(review["rating"])
      if rating.len > 0:
        ratingCounts[rating] = ratingCounts.getOrDefault(rating, 0) + 1
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
    if review.hasKey("sentiment"):
      let sentiment = $(review["sentiment"])
      sentimentCounts[sentiment] = sentimentCounts.getOrDefault(sentiment, 0) + 1
    
    # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ ÑĞ»Ğ¾Ğ²
    if review.hasKey("word_count"):
      let wc = $(review["word_count"])
      try:
        totalWordCount += parseInt(wc)
      except:
        discard
  
  echo "  ğŸ“ˆ RATINGS DISTRIBUTION:"
  for rating in ["10", "9", "8", "7", "6", "5", "4", "3", "2", "1"]:
    if ratingCounts.hasKey(rating):
      let count = ratingCounts[rating]
      let bar = "â–ˆ".repeat(count)
      echo "     ", rating, "/10: ", bar, " (", count, ")"
  
  echo ""
  echo "  ğŸ˜Š SENTIMENT ANALYSIS:"
  for sentiment in ["positive", "neutral", "negative", "unknown"]:
    if sentimentCounts.hasKey(sentiment):
      let count = sentimentCounts[sentiment]
      echo "     ", sentiment.capitalizeAscii(), ": ", count
  
  echo ""
  echo "  âœï¸  AVERAGE REVIEW LENGTH: ", 
    if scraper.allReviews.len > 0:
      $(totalWordCount div scraper.allReviews.len) & " words"
    else: "N/A"
  echo ""

proc printSampleReviews(scraper: IMDBReviewsScraper, count: int = 2) =
  ## Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SAMPLE REVIEWS"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  
  let samplesToShow = min(count, scraper.allReviews.len)
  
  for i in 0..<samplesToShow:
    let review = scraper.allReviews[i]
    
    echo "  â”Œâ”€ Review #", i + 1, " ", "â”€".repeat(60)
    
    if review.hasKey("title"):
      echo "  â”‚ ğŸ“Œ Title: ", $(review["title"])
    
    if review.hasKey("rating"):
      echo "  â”‚ â­ Rating: ", $(review["rating"]), "/10"
    
    if review.hasKey("author"):
      echo "  â”‚ ğŸ‘¤ Author: ", $(review["author"])
    
    if review.hasKey("review_date"):
      echo "  â”‚ ğŸ“… Date: ", $(review["review_date"])
    
    if review.hasKey("sentiment"):
      echo "  â”‚ ğŸ˜Š Sentiment: ", $(review["sentiment"])
    
    if review.hasKey("word_count"):
      echo "  â”‚ âœï¸  Words: ", $(review["word_count"])
    
    if review.hasKey("review_text"):
      var text = $(review["review_text"])
      if text.len > 200:
        text = text[0..200] & "..."
      echo "  â”‚"
      echo "  â”‚ ğŸ“ Review:"
      for line in text.split("\n"):
        if line.strip().len > 0:
          echo "  â”‚    ", line
    
    echo "  â””â”€", "â”€".repeat(70)
    echo ""

# ============================================================================
# MAIN - Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°
# ============================================================================

proc main() {.async.} =
  echo """
  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘                                                                        â•‘
  â•‘              IMDB REVIEWS SCRAPER - NimBrowser Demo                    â•‘
  â•‘                                                                        â•‘
  â•‘  Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ NimBrowser v1.0                 â•‘
  â•‘                                                                        â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  """
  echo ""
  
  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞºÑ€ĞµĞ¹Ğ¿ĞµÑ€Ğ°
  let scraper = newIMDBReviewsScraper()
  
  # Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ĞºÑÑˆĞ° ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²
  enableQueryCache()
  echo "âœ“ Query cache enabled"
  echo ""
  
  # Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞºÑ€ĞµĞ¹Ğ¿Ğ¸Ğ½Ğ³Ğ°
  await scraper.scrapeAllPages()
  
  # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
  scraper.exportResults()
  
  # Ğ’Ñ‹Ğ²Ğ¾Ğ´ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
  scraper.printStatistics()
  
  # Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²
  scraper.printSampleReviews(2)
  
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "â•‘ SCRAPING COMPLETED SUCCESSFULLY! ğŸ‰"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""
  echo "Files created:"
  echo "  â€¢ imdb_reviews.json  - ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ JSON Ğ¼Ğ°ÑÑĞ¸Ğ²"
  echo "  â€¢ imdb_reviews.jsonl - JSON Lines Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚"
  echo "  â€¢ imdb_reviews.csv   - CSV Ñ„Ğ°Ğ¹Ğ»"
  echo ""

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹
when isMainModule:
  waitFor main()

## ============================================================================
## Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ˜ ĞŸĞ Ğ—ĞĞŸĞ£Ğ¡ĞšĞ£
## ============================================================================
##
## 1. Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ñƒ Ğ²Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Nim (Ğ²ĞµÑ€ÑĞ¸Ñ 2.2.6 Ğ¸Ğ»Ğ¸ Ğ²Ñ‹ÑˆĞµ)
##
## 2. Ğ¡ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ:
##    nim c -d:release imdb_reviews_scraper.nim
##
## 3. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ:
##    ./imdb_reviews_scraper
##
## ĞŸĞ Ğ˜ĞœĞ•Ğ§ĞĞĞ˜Ğ•: ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ HTTP-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº IMDB.
## Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸:
##   - Ğ¡Ğ¾Ğ±Ğ»ÑĞ´Ğ°Ğ¹Ñ‚Ğµ robots.txt ÑĞ°Ğ¹Ñ‚Ğ° IMDB
##   - Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 2000Ğ¼Ñ)
##   - ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ MAX_PAGES Ğ´Ğ»Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†
##   - ĞŸÑ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ¸
##   - Ğ‘ÑƒĞ´ÑŒÑ‚Ğµ ÑƒĞ²Ğ°Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹ Ğº ÑĞµÑ€Ğ²ĞµÑ€Ğ°Ğ¼ IMDB - Ğ½Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½ÑƒÑ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ
##
## ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°:
##   - MOVIE_ID - ID Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ° Ğ½Ğ° IMDB (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, "tt0181852")
##   - MAX_PAGES - Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸
##   - REQUEST_DELAY - Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ² Ğ¼Ğ¸Ğ»Ğ»Ğ¸ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
##
## ============================================================================
